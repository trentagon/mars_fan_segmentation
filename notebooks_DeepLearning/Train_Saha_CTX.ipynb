{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a code to locally train the deep learning model but it takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile\n",
    "from supercloudUtils import train_model, segment_image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from time import perf_counter\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m saveModelPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/results/CTX_only/models/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(name_list) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     33\u001b[0m saveResultPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/results/CTX_only/images/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(name_list) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 34\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_img\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model,saveModelPath) \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#model = torch.load(saveModelPath)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ESS569/MLGEO2024_MarsFans/notebooks_Research/supercloudUtils.py:174\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(inputImage, trainingEpochs, batchSize, finalFeatures, patchSize)\u001b[0m\n\u001b[1;32m    171\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    173\u001b[0m projection1, projection2 \u001b[38;5;241m=\u001b[39m model(data1ForModelTraining, data2ForModelTraining)\n\u001b[0;32m--> 174\u001b[0m _,projection2Shuffled \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata1ForModelTraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata2ForModelTrainingShuffled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m _,prediction1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(projection1,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    177\u001b[0m _,prediction2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(projection2,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/saha_seg/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/saha_seg/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ESS569/MLGEO2024_MarsFans/notebooks_Research/networksVaryingKernel.py:122\u001b[0m, in \u001b[0;36mModel5ChannelInitialToMiddleLayersDifferent.forward\u001b[0;34m(self, xModality1, xModality2)\u001b[0m\n\u001b[1;32m    120\u001b[0m xModality1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu( xModality1 )\n\u001b[1;32m    121\u001b[0m xModality1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3Modality1(xModality1)\n\u001b[0;32m--> 122\u001b[0m xModality1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4Modality1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxModality1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m xModality1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu( xModality1 )\n\u001b[1;32m    124\u001b[0m xModality1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn4Modality1(xModality1)\n",
      "File \u001b[0;32m~/mambaforge/envs/saha_seg/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/saha_seg/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/saha_seg/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/saha_seg/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/data/ai_ready/\" # This is an example, change it to your own path\n",
    "\n",
    "i = 0\n",
    "tic = perf_counter()\n",
    "for ctxIMG in range(2):\n",
    "    for ctxDEM in range(2):\n",
    "        for ctxSLOPE in range(2):\n",
    "                tic_inner = perf_counter()\n",
    "                name_list = []\n",
    "                training_img = []\n",
    "                if ctxIMG:\n",
    "                    img = tifffile.imread(data_path + \"ctxIMG_aiready.tif\")\n",
    "                    training_img.append(img)\n",
    "                    name_list.append('ctxIMG')\n",
    "                if ctxDEM:\n",
    "                    img = tifffile.imread(data_path + \"ctxDEM_aiready.tif\")\n",
    "                    training_img.append(img)\n",
    "                    name_list.append('ctxDEM')\n",
    "                if ctxSLOPE:\n",
    "                    img = tifffile.imread(data_path + \"ctxSLOPE_aiready.tif\")\n",
    "                    training_img.append(img)\n",
    "                    name_list.append('ctxSLOPE')\n",
    "\n",
    "                if ~np.any(training_img): # handle the case where no data is selected\n",
    "                                        continue\n",
    "\n",
    "                s = np.shape(training_img) # need at least 2 channels\n",
    "                if s[0] <= 1:\n",
    "                    continue\n",
    "\n",
    "                training_img = np.transpose(training_img,(1,2,0))\n",
    "                saveModelPath = '/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/results/CTX_only/models/' + '_'.join(name_list) + '.pth'\n",
    "                saveResultPath = '/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/results/CTX_only/images/' + '_'.join(name_list) + '.png'\n",
    "                model = train_model(training_img) # Train model\n",
    "                torch.save(model,saveModelPath) # Save model\n",
    "                #model = torch.load(saveModelPath)\n",
    "                result = segment_image(training_img, model) # Segment image\n",
    "                plt.imsave(saveResultPath,result) # Save segmented image\n",
    "\n",
    "                toc_inner = perf_counter()\n",
    "                i = i+1\n",
    "                print(\"Iteration \",i,\" complete in %.2f minutes\" % round((toc_inner-tic_inner)/(60),2))\n",
    "\n",
    "                trainingEpochs = 4\n",
    "                batchSize = 8\n",
    "                # finalFeatures_grid = [4,6,8,10]\n",
    "                # patchSize_grid = [448,336,224]\n",
    "                finalFeatures_grid = [8]\n",
    "                patchSize_grid = [336]\n",
    "                \n",
    "                for finalFeatures in finalFeatures_grid:\n",
    "                    for patchSize in patchSize_grid:\n",
    "                        tic_inner = perf_counter()\n",
    "                        \n",
    "                        hyper_str = \"_ff\" + str(finalFeatures) + \"_ps\" + str(patchSize)\n",
    "                        \n",
    "                        saveModelPath = '/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/results/CTX_only/models/' + '_'.join(name_list) + hyper_str + '.pth'\n",
    "                        saveResultPath = '/Users/tthomas/Desktop/ESS569/MLGEO2024_MarsFans/results/CTX_only/images/' + '_'.join(name_list) + hyper_str + '.png'\n",
    "                        \n",
    "                        model = train_model(training_img,trainingEpochs=trainingEpochs,batchSize=batchSize,\n",
    "                                            finalFeatures=finalFeatures,patchSize=patchSize) # Train model\n",
    "                        torch.save(model,saveModelPath) # Save model\n",
    "                        #model = torch.load(saveModelPath)\n",
    "                        result = segment_image(training_img, model) # Segment image\n",
    "                        plt.imsave(saveResultPath,result) # Save segmented image\n",
    "\n",
    "                        toc_inner = perf_counter()\n",
    "                        i = i+1\n",
    "                        print(\"Iteration \",i,\" complete in %.2f minutes\" % round((toc_inner-tic_inner)/(60),2))\n",
    "\n",
    "toc = perf_counter()\n",
    "print(\"Iterations:\",i)\n",
    "print(\"Elapsed: %.2f s\" % round((toc-tic),2))\n",
    "print(\"Elapsed: %.2f min\" % round((toc-tic)/60,2))\n",
    "print(\"Elapsed: %.2f hr\" % round((toc-tic)/(60*60),2))\n",
    "print(\"Elapsed: %.2f day\" % round((toc-tic)/(60*60*24),2))\n",
    "print(\"Minutes per iteration: %.2f\" % round(((toc-tic)/(60))/i,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saha_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
